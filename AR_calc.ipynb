{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718fbfcb-51e8-49a6-96a2-0990dc197503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import re\n",
    "from names_dataset import NameDataset\n",
    "import time\n",
    "import datetime \n",
    "import import_data\n",
    "import matplotlib.pyplot as plt\n",
    "import gender_classification\n",
    "import calculate_AR\n",
    "import ttest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime \n",
    "import LinearReg\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "path = \"/Users/admin/Documents/Interd Project/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0243c0fc-4cc9-411e-a6de-f914d9b5cc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions without ISIN Code: 6. TICKERS: ['PBBI']\n",
      "121\n",
      "DF shape after dropping companies, for which we don't have daily returns: (589698, 9)\n",
      "(571763, 9)\n",
      "Number of transactions after June 23 (too recent): 8060\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(path +\"df_incl_gender.pkl\")\n",
    "df = df[df[\"Gender\"]!=\"na\"]\n",
    "\n",
    "DR_companies = pd.read_pickle(path + \"DR_companies.pkl\")\n",
    "DR_market = pd.read_pickle(path + \"DR_market.pkl\")\n",
    "\n",
    "isin = pd.read_excel(path+ 'ISIN_merge.xlsx') \n",
    "df = df.merge(isin,left_on=\"Ticker\", right_on=\"TICKER SYMBOL\", how='left').drop(columns=\"TICKER SYMBOL\")\n",
    "\n",
    "not_found = df[df[\"ISIN CODE\"].isna()]\n",
    "print(\"Transactions without ISIN Code: \" +str(len(not_found))+ \". TICKERS: \" + str(not_found[\"Ticker\"].unique()))\n",
    "df.dropna(subset=['ISIN CODE'], inplace=True)\n",
    "\n",
    "df_isins = df[\"ISIN CODE\"].tolist()\n",
    "dr_isins = DR_companies.index.values.tolist()\n",
    "\n",
    "isin_not_in_dr = set(df_isins)-set(dr_isins)\n",
    "print(len(isin_not_in_dr))\n",
    "pd.DataFrame(isin_not_in_dr).to_excel(path+\"ISIN_noinDR.xlsx\")\n",
    "df = df[~df['ISIN CODE'].isin(isin_not_in_dr)]\n",
    "print(\"DF shape after dropping companies, for which we don't have daily returns: \" + str(df.shape))\n",
    "\n",
    "df[\"Filing Date\"] = df['Filing Date'].apply(lambda x: pd.to_datetime(x).normalize())\n",
    "DD_sameDay_samePerson = df[df.duplicated(subset=['Filing Date', 'Insider Name','Ticker','Trade Type'],keep=False)].to_excel(path + \"DD_sameDayPerson.xlsx\")\n",
    "df.drop_duplicates(subset=['Filing Date', 'Insider Name','Ticker','Trade Type'], keep='first',inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "# some more preprocessing before calculating the individual Abnormal Returns\n",
    "# we need to drop all transactions that are too recent, wo we cannot calculate event window\n",
    "print(\"Number of transactions after June 23 (too recent): \" + str(len(df[df['Filing Date'] > \"2023-06-01 00:00:00\"])))\n",
    "df[df['Filing Date'] > \"2023-06-01 00:00:00\"].to_excel(path+\"FilingDate_toorecent.xlsx\")\n",
    "df = df.drop(df[df['Filing Date'] > \"2023-06-01 00:00:00\"].index)\n",
    "\n",
    "#infinite values cannot be processed, we replace them with nan values\n",
    "DR_companies.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e89e7a29-f1b8-4e9b-aa19-2eb2a86872a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_notin_dr = 0 \n",
    "\n",
    "def calc_windows(event_day,dr,L1,L2):\n",
    "    \n",
    "    if event_day not in dr:\n",
    "        return pd.DataFrame(np.zeros((1, 200))).astype(\"float32\"),pd.DataFrame(np.zeros((1, 41))).astype(\"float32\")\n",
    "        print(event_day)\n",
    "        date_notin_dr+=1\n",
    "    #same index for market and company\n",
    "    event_index = dr.columns.get_loc(event_day)\n",
    "\n",
    "    T1_index = (event_index-1)-L2\n",
    "    T2_index = (event_index)+L2\n",
    "    T0_index = T1_index-L1\n",
    "    T3_index = T2_index+L1\n",
    "    #print(event_day,T0_index, T1_index,T2_index,T3_index) \n",
    "\n",
    "    \n",
    "    # Estimation window\n",
    "    estimation_window = dr.iloc[:,T0_index:T1_index]\n",
    "    estimation_window.transpose().dropna(thresh=100,inplace=True)\n",
    "    \n",
    "    #estimation_window.transpose().fillna(method=\"bfill\",inplace=True)\n",
    "    #estimation_window.transpose().fillna(method=\"ffill\",inplace=True)\n",
    "    #print(estimation_window.shape)\n",
    "\n",
    "    # Event-Window\n",
    "    event_window = dr.iloc[:,T1_index:T2_index]\n",
    "    #print(event_window.shape)\n",
    "    \n",
    "    return estimation_window,event_window\n",
    "\n",
    "\n",
    "def calc_linreg(X_train,y_train,X_test,y_test):\n",
    "    xmean= np.mean(X_train)\n",
    "    ymean= np.mean(y_train)\n",
    "    X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "    #print(X_train)\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    X_test = np.c_[np.ones(X_test.shape[0]), X_test]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    b = model.coef_[1]\n",
    "    residuals = (y_test-y_pred)\n",
    "    a = (xmean)-(b*ymean)\n",
    "\n",
    "    return a,b,residuals\n",
    "\n",
    "def gunnar_run(X,Y):\n",
    "    \n",
    "    # add a constant to the X matrix\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # calculate the coefficients\n",
    "    beta = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "\n",
    "    # calculate the residuals\n",
    "    eps = Y - X @ beta\n",
    "\n",
    "    return beta[0], beta[1], eps\n",
    "\n",
    "def run_calculation_AR(date,cr,mr, L1 = 200, L2 = 20):\n",
    "    \n",
    "    cr = pd.DataFrame(cr).transpose()\n",
    "    \n",
    "    est_window_market,event_window_market = calc_windows(date,mr,L1,L2)\n",
    "    est_window_comp,event_window_comp = calc_windows(date,cr,L1,L2)\n",
    "    return est_window_comp,event_window_comp \n",
    "\n",
    "    if (est_window_market.isnull().values.all() or est_window_comp.isnull().values.any()):\n",
    "        print(est_window_market.iloc[:,-1:])\n",
    "        print(est_window_comp.iloc[:,-1:])\n",
    "        return pd.DataFrame(np.zeros((1, 41))).astype(\"float32\")\n",
    "    \n",
    "    #return est_window_market,event_window_market,est_window_comp,event_window_comp\n",
    "\n",
    "    a,b,eps = calc_linreg(est_window_market.values[0,:],est_window_comp.values[0,:],event_window_market.values[0,:],event_window_comp.values[0,:])\n",
    "    #a,b,eps = gunnar_run(est_window_market.values[0,:],est_window_comp.values[0,:])\n",
    "    #coefs,interc,residuals = calc_linreg(est_window_market.values[0,:],est_window_comp.values[0,:])\n",
    "    AR = event_window_comp.values - a - (b*event_window_market.values)\n",
    "    #print(coefs,interc,residuals)\n",
    "   \n",
    "    return AR,eps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e057e1b9-9f0e-4294-bf63-fee79acbe586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mr = DR_market[:1]\n",
    "cols = [str(item)for item in range(-20,21)]\n",
    "start_time = time.time()\n",
    "epses = []\n",
    "empty = pd.DataFrame(np.zeros((1, 41))).astype(\"float32\")\n",
    "empty_all = []\n",
    "\n",
    "\n",
    "ARs = pd.DataFrame()\n",
    "    \n",
    "count = 0\n",
    "\n",
    "for v in df.values[:100,:]:\n",
    "\n",
    "    event_date = v[0]\n",
    "    isin = v[-1]\n",
    "\n",
    "    cr = DR_companies.loc[isin]\n",
    "\n",
    "    #abnormal_returns,eps = run_calculation_AR(event_date,cr,mr)\n",
    "    est_c,ev_c = run_calculation_AR(event_date,cr,mr)\n",
    "    check_if_empty = (abnormal_returns == empty).all()\n",
    "    if (check_if_empty == True).all():\n",
    "        empty_all.append(abnormal_returns)\n",
    "        continue\n",
    "\n",
    "    ARs = pd.concat([ARs,pd.DataFrame(abnormal_returns)])\n",
    "    epses.append(eps)\n",
    "    count+=1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "04818600-857b-4aa6-995f-8c15e10bd530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if not (est_c.transpose().isna().sum().all()>100):\n",
    "    print (\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea8117-6ec9-416c-b565-209d96a4104b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
